{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Parameter Fitting\n\nThis example shows how to use TorchSim to perform parameter inference.\n\nWe will build on the previous example. We will use ``numba``, which can \nbe installed as ``pip install numba``\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-info'>\n\n# Install libraries needed for Colab\n\nThe below installation commands are needed to be run only on Google Colab.\n</div>\n<div class=\"colab-button\">\n            <a href=\"https://colab.research.google.com/github/INFN-MRI/torchsim/blob/gh-pages/examples/generated/autoexamples/03-fitting.ipynb\" target=\"_blank\">\n                <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" \n                alt=\"Open In Colab\"/>\n            </a>\n        </div>\n        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Install libraries\n!pip install torchsim torchio sigpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll generate an FSE dataset from IXI database.\nWe will neglect encoding and assume single coil for this case.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport numpy as np\nimport torchio as tio\nimport torchsim\n\npath = os.path.realpath(\"data\")\nixi_dataset = tio.datasets.IXI(\n    path,\n    modalities=(\"PD\", \"T2\"),\n    download=False,\n)\n\n# get subject 0\nsample_subject = ixi_dataset[0]\n\nM0 = sample_subject.PD.numpy().astype(np.float32).squeeze()[:, :, 60].T\nT2w = sample_subject.T2.numpy().astype(np.float32).squeeze()[:, :, 60].T\n\nsa = np.sin(np.deg2rad(8.0))\nta = np.tan(np.deg2rad(8.0))\n\nT2 = -92.0 / np.log(T2w / M0)\nT2 = np.nan_to_num(T2, neginf=0.0, posinf=0.0)\nT2 = np.clip(T2, a_min=0.0, a_max=np.inf)\n\nM0 = np.flip(M0)\nT2 = np.flip(T2)\n\n\ndef simulate(T2, flip, ESP, device=\"cpu\"):\n    # get ishape\n    ishape = T2.shape\n    output = torchsim.fse_sim(\n        flip=flip, ESP=ESP, T1=1000.0, T2=T2.flatten(), device=device\n    )\n\n    return abs(output.T.reshape(-1, *ishape)).numpy(force=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now generate the data\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flip = 180.0 * np.ones(32, dtype=np.float32)\nESP = 5.0\ndevice = \"cpu\"\n\n# simulate acquisition\necho_series = M0 * simulate(T2, flip.copy(), ESP, device=device)\n\n# display\nimg = np.concatenate((echo_series[0], echo_series[16], echo_series[-1]), axis=1)\n\nimport matplotlib.pyplot as plt\n\nplt.imshow(abs(img), cmap=\"gray\"), plt.axis(\"image\"), plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now, we want to implement a simple dictionary based inference algorithm.\nWe first need a container to store the dictionary. We'll use Python dataclasses for this:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n\n\n@dataclass\nclass BlochDictionary:\n    atoms: np.ndarray\n    lookup_table: np.ndarray\n    labels: list\n\n    def __post_init__(self):\n        self.atoms = np.ascontiguousarray(self.atoms.transpose())\n        self.norm = np.linalg.norm(self.atoms, axis=0)\n        self.atoms = self.atoms / self.norm\n        self.lookup_table = np.ascontiguousarray(self.lookup_table.transpose())\n        self.labels = list(self.labels)\n\n    def to(self, device):\n        self.atoms = self.atoms.to(device)\n        self.norm = self.norm.to(device)\n        self.lookup_table = self.lookup_table.to(device)\n        return self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we implement a simple exhaustive search algorithm. We'll use Numba to parallelize it\nacross different voxels:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numba as nb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the main algorithm. We select matching entry using dot product\nas a cost function:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _matching(signals, atoms, labels):\n    \"\"\"\n    performs pattern matching step.\n    \"\"\"\n    # preallocate\n    cost = np.zeros(signals.shape[0], dtype=np.complex64)\n    idx = np.zeros(signals.shape[0], dtype=int)\n\n    # do actual matching\n    _dot_search(signals, atoms, cost, idx)\n\n    return labels[:, idx], cost, idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to implement the dot search:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@nb.njit(fastmath=True, parallel=True)  # pragma: no cover\ndef _dot_search(time_series, dictionary, cost, idx):\n    for n in nb.prange(time_series.shape[0]):\n        for a in range(dictionary.shape[0]):\n            value = _dot_product(time_series[n], dictionary[a])\n\n            # keep maximum value\n            if np.abs(value) > np.abs(cost[n]):\n                cost[n] = value\n                idx[n] = a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we implement a trivial dot product, compatible with numba:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@nb.njit(fastmath=True, cache=True)  # pragma: no cover\ndef _dot_product(x, y):\n    z = 0.0\n    for n in range(x.shape[0]):\n        z += x[n] * y[n]\n\n    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create a wrapper to handle arbitrarily shaped inputs:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def matching(bloch_dict, time_series):\n    shape = time_series.shape[1:]\n    time_series = time_series.reshape((time_series.shape[0], np.prod(shape)))\n    time_series = np.ascontiguousarray(time_series.transpose().conj())\n\n    # get atoms\n    atoms = np.ascontiguousarray(bloch_dict.atoms.transpose())\n    labels = bloch_dict.lookup_table\n\n    # get quantitative maps and proton density\n    qmaps, cost, idx = _matching(time_series, atoms, labels)\n    qmaps = qmaps.reshape([qmaps.shape[0]] + list(shape))\n    qmaps = [qmap for qmap in qmaps]\n    m0 = (cost / bloch_dict.norm[idx]).reshape(shape)\n\n    return m0, dict(zip(bloch_dict.labels, qmaps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can assume the above code to be in a library. We now want to\nintegrate it with our signal model from epg-torch-x. This can be done\nas:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\n\ndef fse_fit(input, t2grid, flip, ESP, phases=None):\n    if isinstance(input, torch.Tensor):\n        istorch = True\n        device = input.device\n        input = input.numpy(force=True)\n    else:\n        istorch = False\n\n    # default\n    if phases is None:\n        phases = -np.ones_like(flip) * 90.0\n\n    # first build grid\n    t2lut = np.linspace(t2grid[0], t2grid[1], t2grid[2])\n    t1 = 1000.0\n\n    # build dictionary\n    atoms = torchsim.fse_sim(flip=flip, phases=phases, ESP=ESP, T1=t1, T2=t2lut).numpy(\n        force=True\n    )\n    blochdict = BlochDictionary(abs(atoms), t2lut[:, None], [\"T2\"])\n\n    # perform matching\n    m0, maps = matching(blochdict, input)\n\n    # here, we only have T2\n    t2map = maps[\"T2\"]\n\n    # cast back\n    if istorch:\n        m0 = torch.as_tensor(m0, device=device)\n        t2map = torch.as_tensor(t2map, device=device)\n\n    return m0, t2map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Done! We can now try it:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "M0rec, T2rec = fse_fit(echo_series.copy(), (1.0, 350.0, 1000), flip.copy(), ESP)\n\nplt.subplot(2, 2, 1)\nplt.imshow(T2, vmax=350.0), plt.axis(\"off\"), plt.colorbar(), plt.title(\"true T2 [ms]\")\nplt.subplot(2, 2, 2)\nplt.imshow(T2rec, vmax=350.0), plt.axis(\"off\"), plt.colorbar(), plt.title(\n    \"recon T2 [ms]\"\n)\nplt.subplot(2, 2, 3)\nplt.imshow(M0, cmap=\"gray\"), plt.axis(\"off\"), plt.colorbar(), plt.title(\"true M0\")\nplt.subplot(2, 2, 4)\nplt.imshow(abs(M0rec), cmap=\"gray\"), plt.axis(\"off\"), plt.colorbar(), plt.title(\n    \"recon M0\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}